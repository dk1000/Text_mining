{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTOeC7MXDV37"
   },
   "outputs": [],
   "source": [
    "# biblioteki\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ZvIN8Q2DdTB"
   },
   "outputs": [],
   "source": [
    "# dane\n",
    "url = 'https://raw.githubusercontent.com/dk1000/Warsztaty_Jaroszewicz/master/train.tsv'\n",
    "train = pd.read_csv(url, sep=\"\\t\")\n",
    "train = train.fillna(\" \")\n",
    "\n",
    "url1 = \"https://raw.githubusercontent.com/dk1000/Warsztaty_Jaroszewicz/master/test_noy.tsv\"\n",
    "data = pd.read_csv(url1, sep=\"\\t\")\n",
    "data = data.fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3b5qQTdEan6"
   },
   "outputs": [],
   "source": [
    "def extract_text_features(s):\n",
    "  s = s.astype(\"str\")\n",
    "  n = s.str.len().values\n",
    "  n_w = s.str.split().str.len()\n",
    "  avg_w_len = n.astype(float)/n_w\n",
    "  return np.column_stack([n, n_w, avg_w_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uAE_f8_xDq_p"
   },
   "outputs": [],
   "source": [
    "Y = train.iloc[:,0]\n",
    "label = Y == \"pants-fire\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1OCnfj4zf-lC"
   },
   "outputs": [],
   "source": [
    "## dodanie zmiennych na train\n",
    "\n",
    "\n",
    "average = []\n",
    "for line in train[\"statement\"]:\n",
    "  words = line.split()\n",
    "  average.append(sum(len(word) for word in words) / len(words))\n",
    "\n",
    "train[\"average\"] = average\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "number = []\n",
    "for line in train[\"statement\"]:\n",
    "  words = line.split()\n",
    "  number.append(len(words))\n",
    "\n",
    "train[\"number\"] = number\n",
    "\n",
    "###\n",
    "\n",
    "user_input = \"million\"\n",
    "\n",
    "million = []\n",
    "for line in train[\"statement\"]:\n",
    "    if user_input in line.split():\n",
    "        million.append(1)\n",
    "    else:\n",
    "        million.append(0)\n",
    "\n",
    "train[\"million\"] = million\n",
    "\n",
    "###\n",
    "\n",
    "user_input = \"percent\"\n",
    "\n",
    "percent = []\n",
    "for line in train[\"statement\"]:\n",
    "    if user_input in line.split():\n",
    "        percent.append(1)\n",
    "    else:\n",
    "        percent.append(0)\n",
    "\n",
    "train[\"percent\"] = percent\n",
    "\n",
    "###\n",
    "\n",
    "user_input = \"Obama\"\n",
    "\n",
    "Obama = []\n",
    "for line in train[\"statement\"]:\n",
    "    if user_input in line.split():\n",
    "        Obama.append(1)\n",
    "    else:\n",
    "        Obama.append(0)\n",
    "\n",
    "train[\"Obama\"] = Obama\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "user_input = \"health\"\n",
    "\n",
    "health = []\n",
    "for line in train[\"statement\"]:\n",
    "    if user_input in line.split():\n",
    "        health.append(1)\n",
    "    else:\n",
    "        health.append(0)\n",
    "\n",
    "train[\"health\"] = health\n",
    "\n",
    "###\n",
    "\n",
    "user_input = \"more\"\n",
    "\n",
    "more = []\n",
    "for line in train[\"statement\"]:\n",
    "    if user_input in line.split():\n",
    "        more.append(1)\n",
    "    else:\n",
    "        more.append(0)\n",
    "\n",
    "train[\"more\"] = more\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "user_input = \"tax\"\n",
    "\n",
    "tax = []\n",
    "for line in train[\"statement\"]:\n",
    "    if user_input in line.split():\n",
    "        tax.append(1)\n",
    "    else:\n",
    "        tax.append(0)\n",
    "\n",
    "train[\"tax\"] = tax\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "user_input = \"health\"\n",
    "\n",
    "subject_health = []\n",
    "for line in train[\"subject\"]:\n",
    "    if user_input in line.split():\n",
    "        subject_health.append(1)\n",
    "    else:\n",
    "        subject_health.append(0)\n",
    "\n",
    "train[\"subject_health\"] = subject_health\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "user_input = \"economy\"\n",
    "\n",
    "subject_economy = []\n",
    "for line in train[\"subject\"]:\n",
    "    if user_input in line.split():\n",
    "        subject_economy.append(1)\n",
    "    else:\n",
    "        subject_economy.append(0)\n",
    "\n",
    "train[\"subject_economy\"] = subject_economy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRJTKS9uf-lH"
   },
   "outputs": [],
   "source": [
    "### dodanie zmiennych na test_noy\n",
    "\n",
    "average = []\n",
    "for line in data[\"statement\"]:\n",
    "  words = line.split()\n",
    "  average.append(sum(len(word) for word in words) / len(words))\n",
    "\n",
    "data[\"average\"] = average\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "number = []\n",
    "for line in data[\"statement\"]:\n",
    "  words = line.split()\n",
    "  number.append(len(words))\n",
    "\n",
    "data[\"number\"] = number\n",
    "\n",
    "###\n",
    "\n",
    "user_input = \"million\"\n",
    "\n",
    "million = []\n",
    "for line in data[\"statement\"]:\n",
    "    if user_input in line.split():\n",
    "        million.append(1)\n",
    "    else:\n",
    "        million.append(0)\n",
    "\n",
    "data[\"million\"] = million\n",
    "\n",
    "###\n",
    "\n",
    "user_input = \"percent\"\n",
    "\n",
    "percent = []\n",
    "for line in data[\"statement\"]:\n",
    "    if user_input in line.split():\n",
    "        percent.append(1)\n",
    "    else:\n",
    "        percent.append(0)\n",
    "\n",
    "data[\"percent\"] = percent\n",
    "\n",
    "###\n",
    "\n",
    "user_input = \"Obama\"\n",
    "\n",
    "Obama = []\n",
    "for line in data[\"statement\"]:\n",
    "    if user_input in line.split():\n",
    "        Obama.append(1)\n",
    "    else:\n",
    "        Obama.append(0)\n",
    "\n",
    "data[\"Obama\"] = Obama\n",
    "\n",
    "###\n",
    "\n",
    "user_input = \"health\"\n",
    "\n",
    "health = []\n",
    "for line in data[\"statement\"]:\n",
    "    if user_input in line.split():\n",
    "        health.append(1)\n",
    "    else:\n",
    "        health.append(0)\n",
    "\n",
    "data[\"health\"] = health\n",
    "\n",
    "###\n",
    "\n",
    "user_input = \"more\"\n",
    "\n",
    "more = []\n",
    "for line in data[\"statement\"]:\n",
    "    if user_input in line.split():\n",
    "        more.append(1)\n",
    "    else:\n",
    "        more.append(0)\n",
    "\n",
    "data[\"more\"] = more\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "user_input = \"tax\"\n",
    "\n",
    "tax = []\n",
    "for line in data[\"statement\"]:\n",
    "    if user_input in line.split():\n",
    "        tax.append(1)\n",
    "    else:\n",
    "        tax.append(0)\n",
    "\n",
    "data[\"tax\"] = tax\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "user_input = \"health\"\n",
    "\n",
    "subject_health = []\n",
    "for line in data[\"subject\"]:\n",
    "    if user_input in line.split():\n",
    "        subject_health.append(1)\n",
    "    else:\n",
    "        subject_health.append(0)\n",
    "\n",
    "data[\"subject_health\"] = subject_health\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "user_input = \"economy\"\n",
    "\n",
    "subject_economy = []\n",
    "for line in data[\"subject\"]:\n",
    "    if user_input in line.split():\n",
    "        subject_economy.append(1)\n",
    "    else:\n",
    "        subject_economy.append(0)\n",
    "\n",
    "data[\"subject_economy\"] = subject_economy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xu4895Snf-lM",
    "outputId": "717a4d76-c585-4fab-d25d-c3111e574182"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7591343434118688\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver = 'newton-cg', penalty = \"l2\", C = 0.5, n_jobs = -1)\n",
    "\n",
    "\n",
    "ct = ColumnTransformer([(\"statement\", TfidfVectorizer(stop_words = \"english\"), \"statement\"),\n",
    "                        (\"statement_svd1\", Pipeline([(\"TFIDF\", TfidfVectorizer()), (\"svd\", TruncatedSVD(n_components=1000, n_iter=10))]), \"statement\"),\n",
    "                        (\"statement_svd2\", Pipeline([(\"TFIDF\", TfidfVectorizer()), (\"svd\", TruncatedSVD(n_components=500, n_iter=10))]), \"statement\"),\n",
    "                        (\"statement_svd3\", Pipeline([(\"TFIDF\", TfidfVectorizer()), (\"svd\", TruncatedSVD(n_components=100, n_iter=10))]), \"statement\"),\n",
    "                        (\"funcTrans\", FunctionTransformer(func=extract_text_features, validate=False, accept_sparse = True), \"statement\"),\n",
    "                        (\"party\", TfidfVectorizer(), \"party\"),\n",
    "                        (\"context\", TfidfVectorizer(ngram_range = (1,2)), \"context\"),\n",
    "                        (\"speaker_job\", HashingVectorizer(), \"speaker_job\"),\n",
    "                        (\"speaker\", TfidfVectorizer(ngram_range = (1,2)), \"speaker\"),\n",
    "                        (\"subject\", TfidfVectorizer(), \"subject\"),\n",
    "                        (\"avg_length\", \"passthrough\", [\"average\"]),\n",
    "                        (\"number_words\", \"passthrough\", [\"number\"]),\n",
    "                        (\"statement_percent\", \"passthrough\", [\"percent\"]),\n",
    "                        (\"statement_Obama\", \"passthrough\", [\"Obama\"]),\n",
    "                        (\"statement_health\", \"passthrough\", [\"health\"]),\n",
    "                        (\"statement_million\", \"passthrough\", [\"million\"]),\n",
    "                        (\"statement_tax\", \"passthrough\", [\"tax\"]),\n",
    "                        (\"subject_health\", \"passthrough\", [\"subject_health\"]),\n",
    "                        (\"subject_economy\", \"passthrough\", [\"subject_economy\"])\n",
    "                       ])\n",
    "\n",
    "p = Pipeline([(\"columntransformer\", ct), (\"logistic\", model)])\n",
    "\n",
    "scores = cross_val_score(p, train, label, cv=10, scoring = 'roc_auc')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_Mi-I1FfPlz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### zapisanie wyników\n",
    "\n",
    "p.fit(train, label)\n",
    "wynik = p.decision_function(data)\n",
    "#print(wynik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dPzaW4KuI6-8"
   },
   "outputs": [],
   "source": [
    "np.savetxt('wynik.res', wynik, delimiter = \",\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Model_final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
